{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imagenet Training MobileNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "# Just some functions to average stuff, and save the model\n",
    "from utils_pretrain import *\n",
    "\n",
    "# Trainning parameters\n",
    "learning_rate = 0.1\n",
    "batch_size = 64\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "workers = 4\n",
    "print_freq = 100\n",
    "epochs = 1\n",
    "\n",
    "# Define your data path here\n",
    "IMAGENET_PATH = '/Users/darshangadkari/Documents/Homeopath/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Mobilenet class\n",
    "#### Architecture\n",
    "![title](ArchMobileNet.png)\n",
    "#### Normal Convolution and Depthwise convolution\n",
    "![title](MobileNetConvs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNet, self).__init__()\n",
    "\n",
    "        # Normal convolution block followed by Batchnorm (CONV_3x3-->BN-->Relu)\n",
    "        def conv_bn(inp, oup, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        # Depthwise convolution block (CONV_BLK_3x3-->BN-->Relu-->CONV_1x1-->BN-->Relu)\n",
    "        def conv_dw(inp, oup, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n",
    "                nn.BatchNorm2d(inp),\n",
    "                nn.ReLU(inplace=True),\n",
    "    \n",
    "                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            conv_bn(  3,  32, 2), \n",
    "            conv_dw( 32,  64, 1),\n",
    "            conv_dw( 64, 128, 2),\n",
    "            conv_dw(128, 128, 1),\n",
    "            conv_dw(128, 256, 2),\n",
    "            conv_dw(256, 256, 1),\n",
    "            conv_dw(256, 512, 2),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 1024, 2),\n",
    "            conv_dw(1024, 1024, 1),\n",
    "            nn.AvgPool2d(7),\n",
    "        )\n",
    "        self.fc = nn.Linear(1024, 1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model and pass to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNet(\n",
      "  (model): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Sequential(\n",
      "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
      "  )\n",
      "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MobileNet()\n",
    "\n",
    "print(model)\n",
    "\n",
    "# use GPU to accelerate\n",
    "# model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss().cuda()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define solver(SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), learning_rate,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading specifics for ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "# traindir = os.path.join(IMAGENET_PATH, '/trainDrSK/Eczema\\ of\\ Arms/')\n",
    "traindir = f'{IMAGENET_PATH}/trainDrSK/'\n",
    "# valdir = os.path.join(IMAGENET_PATH, '/testDrSK/Eczema\\ of\\ Arms/')\n",
    "valdir = f'{IMAGENET_PATH}/testDrSK/'\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Preprocess the data, Operations that will be done on data\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#         datasets.ImageFolder(traindir, transforms.Compose([\n",
    "#             transforms.RandomResizedCrop(224), #randomly crop image to 224 * 224\n",
    "#             transforms.RandomHorizontalFlip(), \n",
    "#             transforms.RandomVerticalFlip(), \n",
    "#             transforms.RandomRotation(10), \n",
    "#             transforms.ColorJitter(0.05, 0.05, 0.05, 0.05), \n",
    "#             transforms.ToTensor(), \n",
    "#             normalize,\n",
    "#         ])),\n",
    "#         batch_size=batch_size, shuffle=True,\n",
    "#         num_workers=workers, pin_memory=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(traindir, transform=ToTensor()),\n",
    "        batch_size=batch_size, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.ImageFolder(valdir, transforms.Compose([\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize,\n",
    "#     ])),\n",
    "#     batch_size=batch_size, shuffle=False,\n",
    "#     num_workers=workers, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transform=ToTensor()),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # target = target.cuda(async=True)\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1, top5=top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/darshangadkari/Documents/Homeopath/code/emap/train.ipynb Cell 15\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/darshangadkari/Documents/Homeopath/code/emap/train.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m adjust_learning_rate(optimizer, epoch, learning_rate)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/darshangadkari/Documents/Homeopath/code/emap/train.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# train for one epoch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/darshangadkari/Documents/Homeopath/code/emap/train.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train(train_loader, model, criterion, optimizer, epoch)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/darshangadkari/Documents/Homeopath/code/emap/train.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# evaluate on validation set\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/darshangadkari/Documents/Homeopath/code/emap/train.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m prec1 \u001b[39m=\u001b[39m validate(val_loader, model, criterion)\n",
      "\u001b[1;32m/Users/darshangadkari/Documents/Homeopath/code/emap/train.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/darshangadkari/Documents/Homeopath/code/emap/train.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target_var)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/darshangadkari/Documents/Homeopath/code/emap/train.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# measure accuracy and record loss\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/darshangadkari/Documents/Homeopath/code/emap/train.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m prec1, prec5 \u001b[39m=\u001b[39m accuracy(output\u001b[39m.\u001b[39;49mdata, target, topk\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m, \u001b[39m5\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/darshangadkari/Documents/Homeopath/code/emap/train.ipynb#X20sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m losses\u001b[39m.\u001b[39mupdate(loss\u001b[39m.\u001b[39mdata[\u001b[39m0\u001b[39m], \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/darshangadkari/Documents/Homeopath/code/emap/train.ipynb#X20sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m top1\u001b[39m.\u001b[39mupdate(prec1[\u001b[39m0\u001b[39m], \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/Homeopath/code/emap/utils_pretrain.py:57\u001b[0m, in \u001b[0;36maccuracy\u001b[0;34m(output, target, topk)\u001b[0m\n\u001b[1;32m     55\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[1;32m     56\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m topk:\n\u001b[0;32m---> 57\u001b[0m     correct_k \u001b[39m=\u001b[39m correct[:k]\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39msum(\u001b[39m0\u001b[39m)\n\u001b[1;32m     58\u001b[0m     res\u001b[39m.\u001b[39mappend(correct_k\u001b[39m.\u001b[39mmul_(\u001b[39m100.0\u001b[39m \u001b[39m/\u001b[39m batch_size))\n\u001b[1;32m     59\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "for epoch in range(0, epochs):\n",
    "        adjust_learning_rate(optimizer, epoch, learning_rate)\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion)\n",
    "\n",
    "        # remember best prec@1 and save checkpoint\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': args.arch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "There are two ways to save the model.\n",
    "\n",
    "**Reference:**\n",
    "\n",
    "http://pytorch.org/docs/0.3.1/notes/serialization.html#recommend-saving-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only save the parameters (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters\n",
    "torch.save(model.state_dict(),\"mobilenet_params.pth.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the whole model\n",
    "torch.save(model, \"mobilenet_model.pth.tar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
